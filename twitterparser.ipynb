{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw4.ipynb","provenance":[],"authorship_tag":"ABX9TyOk+1lNz0d0xhuxw9CJukn+"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"id":"Zn0-z5pVA-63","executionInfo":{"status":"ok","timestamp":1648550735821,"user_tz":-480,"elapsed":774,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"9d59b3ac-9454-40fe-9131-402965350645"},"source":["# Read url\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","\n","import numpy\n","import pandas as pd\n","df = pd.read_csv('https://raw.githubusercontent.com/lkyin/ECS189L/main/Tweets.csv')\n","\n","# Preview\n","df.head()"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n","0  570306133677760513           neutral                        1.0000   \n","1  570301130888122368          positive                        0.3486   \n","2  570301083672813571           neutral                        0.6837   \n","3  570301031407624196          negative                        1.0000   \n","4  570300817074462722          negative                        1.0000   \n","\n","  negativereason  negativereason_confidence         airline  \\\n","0            NaN                        NaN  Virgin America   \n","1            NaN                     0.0000  Virgin America   \n","2            NaN                        NaN  Virgin America   \n","3     Bad Flight                     0.7033  Virgin America   \n","4     Can't Tell                     1.0000  Virgin America   \n","\n","  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n","0                    NaN     cairdin                 NaN              0   \n","1                    NaN    jnardino                 NaN              0   \n","2                    NaN  yvonnalynn                 NaN              0   \n","3                    NaN    jnardino                 NaN              0   \n","4                    NaN    jnardino                 NaN              0   \n","\n","                                                text tweet_coord  \\\n","0                @VirginAmerica What @dhepburn said.         NaN   \n","1  @VirginAmerica plus you've added commercials t...         NaN   \n","2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n","3  @VirginAmerica it's really aggressive to blast...         NaN   \n","4  @VirginAmerica and it's a really big bad thing...         NaN   \n","\n","               tweet_created tweet_location               user_timezone  \n","0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n","1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n","2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n","3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n","4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "],"text/html":["\n","  <div id=\"df-defb763d-0da5-4c71-8927-1cd8c4ee4ef5\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>airline_sentiment</th>\n","      <th>airline_sentiment_confidence</th>\n","      <th>negativereason</th>\n","      <th>negativereason_confidence</th>\n","      <th>airline</th>\n","      <th>airline_sentiment_gold</th>\n","      <th>name</th>\n","      <th>negativereason_gold</th>\n","      <th>retweet_count</th>\n","      <th>text</th>\n","      <th>tweet_coord</th>\n","      <th>tweet_created</th>\n","      <th>tweet_location</th>\n","      <th>user_timezone</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>570306133677760513</td>\n","      <td>neutral</td>\n","      <td>1.0000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>cairdin</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica What @dhepburn said.</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:35:52 -0800</td>\n","      <td>NaN</td>\n","      <td>Eastern Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>570301130888122368</td>\n","      <td>positive</td>\n","      <td>0.3486</td>\n","      <td>NaN</td>\n","      <td>0.0000</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>jnardino</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica plus you've added commercials t...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:15:59 -0800</td>\n","      <td>NaN</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>570301083672813571</td>\n","      <td>neutral</td>\n","      <td>0.6837</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>yvonnalynn</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:15:48 -0800</td>\n","      <td>Lets Play</td>\n","      <td>Central Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>570301031407624196</td>\n","      <td>negative</td>\n","      <td>1.0000</td>\n","      <td>Bad Flight</td>\n","      <td>0.7033</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>jnardino</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica it's really aggressive to blast...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:15:36 -0800</td>\n","      <td>NaN</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>570300817074462722</td>\n","      <td>negative</td>\n","      <td>1.0000</td>\n","      <td>Can't Tell</td>\n","      <td>1.0000</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>jnardino</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica and it's a really big bad thing...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:14:45 -0800</td>\n","      <td>NaN</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-defb763d-0da5-4c71-8927-1cd8c4ee4ef5')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-defb763d-0da5-4c71-8927-1cd8c4ee4ef5 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-defb763d-0da5-4c71-8927-1cd8c4ee4ef5');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-vOkcxrxZsa","executionInfo":{"status":"ok","timestamp":1648550735821,"user_tz":-480,"elapsed":8,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"774d1a91-f4bc-4a49-f497-b7d2d51c7818"},"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from sklearn.feature_extraction.text import CountVectorizer\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","print('Done!')"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","Done!\n"]}]},{"cell_type":"markdown","metadata":{"id":"Sulkc6keJi1s"},"source":["## ***Q1***\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7Lii-iFguM_","outputId":"55c160cf-2546-47b7-c959-3fe252db4433"},"source":["# Q1\n","## initialization\n","Q1_df = df\n","airline_sentiment = df['airline_sentiment']\n","\n","## Store airline names into an array\n","airline_names = df[\"airline\"].unique()\n","\n","## Remove punctuation\n","Q1_df['text'] = Q1_df['text'].str.replace(\"!\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\".\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"#\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\",\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\":\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\")\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"(\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"?\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"-\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"I\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"'\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"&\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\";\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"|\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('”', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('“', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('``', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('\"', \"\")\n","\n","# Stemming\n","from nltk.stem import PorterStemmer\n","ps = PorterStemmer()\n","for index, value in Q1_df['text'].items():\n","  # Lower Case\n","  value = ps.stem(value.lower())\n","  Q1_df['text'].iloc[index] = value\n","\n","## Remove @airline\n","for values in airline_names:\n","  # Add @ sign before airline names\n","  values = \"@\" + values\n","  # Remove empty space\n","  values = values.replace(\" \",\"\")\n","  if (values == \"@American\"):\n","    values = \"@AmericanAir\"\n","  elif (values == \"@Southwest\"):\n","    values = \"@SouthwestAir\"\n","  # Replace\n","  Q1_df['text'] = Q1_df['text'].str.replace(values, \"\")\n","\n","Q1_df['text'] = Q1_df['text'].str.replace(\"@USairways\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"@UsAirways\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"@JetBlue\", \"\")\n","\n","## Remove all lower case @airline\n","Q1_df['text'] = Q1_df['text'].str.replace('@united', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('@jetblue', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('@southwestair', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('@americanair', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('@usairways', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('@virginamerica', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"@\", \"\")\n","\n","# Preview\n","print(\"\\n\")\n","Q1_df['text'].head()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]}]},{"cell_type":"code","metadata":{"id":"veUeXv35OUJK"},"source":["## Split into three sentiment groups: positive, neutral, negative\n","Q1_positive = df[airline_sentiment == 'positive']\n","Q1_neutral = df[airline_sentiment == 'neutral']\n","Q1_negative = df[airline_sentiment == 'negative']\n","\n","## Positive sentiments\n","## Remove stopwords\n","wordlist = []\n","for index, value in Q1_positive['text'].items():\n","  stop_words = set(stopwords.words('english'))\n","  ## Tokenizing\n","  word_tokens = word_tokenize(value)\n","  for w in word_tokens:\n","     if not w in stop_words:\n","       wordlist.append(w)\n","\n","## Report\n","from collections import Counter\n","print(\"Top 10 words used in positive sentiment group are:\")\n","print(Counter(wordlist).most_common(10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4QjIWpf1OXKr"},"source":["## Neutral sentiments\n","## Remove stopwords\n","wordlist = []\n","for index, value in Q1_neutral['text'].items():\n","  stop_words = set(stopwords.words('english'))\n","  ## Tokenizing\n","  word_tokens = word_tokenize(value)\n","  for w in word_tokens:\n","     if not w in stop_words:\n","       wordlist.append(w)\n","\n","## Report\n","print(\"Top 10 words used in neutral sentiment group are:\")\n","print(Counter(wordlist).most_common(10))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x_OcCNXOOaMF"},"source":["## Negative sentiments\n","## Remove stopwords\n","wordlist = []\n","for index, value in Q1_negative['text'].items():\n","  stop_words = set(stopwords.words('english'))\n","  ## Tokenizing\n","  word_tokens = word_tokenize(value)\n","  for w in word_tokens:\n","     if w not in stop_words:\n","       wordlist.append(w)\n","\n","## Report\n","print(\"Top 10 words used in negative sentiment group are:\")\n","print(Counter(wordlist).most_common(10))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x1OPvMNQJsqL"},"source":["## ***Q2***"]},{"cell_type":"code","metadata":{"id":"XKKfQ3BwnhGO"},"source":["# Q2\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import classification_report\n","import numpy as np\n","\n","## Predictors and output\n","X = Q1_df['text']\n","Y = Q1_df['airline_sentiment']\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(X)\n","\n","## Split dataset into 80% for training and 20% for testing\n","## stratify parameter ensures each airline is represented in training and testing data\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify = Y, random_state = 23)\n","\n","## Train\n","model = MultinomialNB()\n","model.fit(X_train, y_train)\n","print('Done Training')\n","\n","## Predict\n","y_pred = model.predict(X_test)\n","report = classification_report(y_test, y_pred, output_dict = True)\n","print(pd.DataFrame(report).transpose())\n","\n","## Cross Validation for not overfitting\n","scores = cross_val_score(model, X, Y, cv=10)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VFVAbHihdcrY"},"source":["## Report\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","print('Accuracy score for this model is: %0.3f' % accuracy_score(y_test, y_pred))\n","print(\"Accuracy score for Cross Validation: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ftLnwtlzJuRI"},"source":["## ***Q3***\n"]},{"cell_type":"code","metadata":{"id":"oOEvxm-QnhIx"},"source":["# Q3\n","# Assuming fraction over number of sentiments specific to each airline\n","airline_names = df[\"airline\"].unique()\n","\n","# Frequency of positive, neutral, and negative sentiment for each airline\n","neg = {\"Virgin America\": 0 ,\"United\" : 0, \"Southwest\":0 , \"Delta\": 0, \"US Airways\" : 0, \"American\" : 0}\n","neutral = {\"Virgin America\": 0 ,\"United\" : 0, \"Southwest\":0 , \"Delta\": 0, \"US Airways\" : 0, \"American\" : 0}\n","pos = {\"Virgin America\": 0 ,\"United\" : 0, \"Southwest\":0 , \"Delta\": 0, \"US Airways\" : 0, \"American\" : 0}\n","\n","# Fraction of positives and negatives for each airline\n","neg_frac = {\"Virgin America\": 0 ,\"United\" : 0, \"Southwest\":0 , \"Delta\": 0, \"US Airways\" : 0, \"American\" : 0}\n","pos_frac = {\"Virgin America\": 0 ,\"United\" : 0, \"Southwest\":0 , \"Delta\": 0, \"US Airways\" : 0, \"American\" : 0}\n","\n","for airline in airline_names:\n","  # Extract airline series\n","  cur_airline = df[df['airline'] == airline]\n","\n","  # Find the frequency for positive, negative, and neutral\n","  counts = cur_airline['airline_sentiment'].value_counts()\n","\n","  # Append each value to our frequency dictionary\n","  neg[airline] = (counts[0])\n","  neutral[airline] = (counts[1])\n","  pos[airline] = (counts[2])\n","\n","  # Calculate total number of sentiments for each airline and calculate fraction\n","  total = counts[0] + counts[1] + counts[2]\n","  neg_frac[airline] = counts[0] / total\n","  pos_frac[airline] = counts[2] / total\n","\n","# Number of positives and negatives for each airline\n","print(\"Negative dict:\", neg)\n","print(\"Positive dict:\", pos)\n","print(\"Neutral dict:\", neutral)\n","\n","# Fraction of positives and negatives for each airline\n","print(\"\\nNegative fraction dict:\", neg_frac)\n","print(\"Positive fraction dict:\", pos_frac)\n","\n","# Sort the dictionary\n","print(\"\\nFraction with Negative sentiments in decreasing value:\")\n","sorted_name_neg = sorted(neg_frac, key=neg_frac.get, reverse = True)\n","for name in sorted_name_neg:\n","    print(name, neg_frac[name])\n","\n","print(\"\\nFraction with positive sentiments in decreasing value:\")\n","sorted_name_neg = sorted(pos_frac, key=pos_frac.get, reverse = True)\n","for name in sorted_name_neg:\n","    print(name, pos_frac[name])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"fD26v_P4dSZV"},"source":["# Report\n","print(\"The top 3 airlines in terms of the fraction of negative tweets are: US Airways, American, United\")\n","print(\"The top 3 airlines in terms of the fraction of positive tweets are: Virgin America, Delta, Southwest\")"],"execution_count":null,"outputs":[]}]}