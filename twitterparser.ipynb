{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"hw4.ipynb","provenance":[],"authorship_tag":"ABX9TyPGR8VW2pvWuwTVkHP2o9n9"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":496},"id":"Zn0-z5pVA-63","executionInfo":{"status":"ok","timestamp":1648549178305,"user_tz":-480,"elapsed":1582,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"f19195e8-244a-482b-ff03-f87e3976a15d"},"source":["# Read url\n","import numpy\n","import pandas as pd\n","df = pd.read_csv('https://raw.githubusercontent.com/lkyin/ECS189L/main/Tweets.csv')\n","\n","# Preview\n","df.head()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n","0  570306133677760513           neutral                        1.0000   \n","1  570301130888122368          positive                        0.3486   \n","2  570301083672813571           neutral                        0.6837   \n","3  570301031407624196          negative                        1.0000   \n","4  570300817074462722          negative                        1.0000   \n","\n","  negativereason  negativereason_confidence         airline  \\\n","0            NaN                        NaN  Virgin America   \n","1            NaN                     0.0000  Virgin America   \n","2            NaN                        NaN  Virgin America   \n","3     Bad Flight                     0.7033  Virgin America   \n","4     Can't Tell                     1.0000  Virgin America   \n","\n","  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n","0                    NaN     cairdin                 NaN              0   \n","1                    NaN    jnardino                 NaN              0   \n","2                    NaN  yvonnalynn                 NaN              0   \n","3                    NaN    jnardino                 NaN              0   \n","4                    NaN    jnardino                 NaN              0   \n","\n","                                                text tweet_coord  \\\n","0                @VirginAmerica What @dhepburn said.         NaN   \n","1  @VirginAmerica plus you've added commercials t...         NaN   \n","2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n","3  @VirginAmerica it's really aggressive to blast...         NaN   \n","4  @VirginAmerica and it's a really big bad thing...         NaN   \n","\n","               tweet_created tweet_location               user_timezone  \n","0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n","1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n","2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n","3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n","4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "],"text/html":["\n","  <div id=\"df-4fa927c9-9cd3-4857-8c22-a41267a0fbec\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>tweet_id</th>\n","      <th>airline_sentiment</th>\n","      <th>airline_sentiment_confidence</th>\n","      <th>negativereason</th>\n","      <th>negativereason_confidence</th>\n","      <th>airline</th>\n","      <th>airline_sentiment_gold</th>\n","      <th>name</th>\n","      <th>negativereason_gold</th>\n","      <th>retweet_count</th>\n","      <th>text</th>\n","      <th>tweet_coord</th>\n","      <th>tweet_created</th>\n","      <th>tweet_location</th>\n","      <th>user_timezone</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>570306133677760513</td>\n","      <td>neutral</td>\n","      <td>1.0000</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>cairdin</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica What @dhepburn said.</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:35:52 -0800</td>\n","      <td>NaN</td>\n","      <td>Eastern Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>570301130888122368</td>\n","      <td>positive</td>\n","      <td>0.3486</td>\n","      <td>NaN</td>\n","      <td>0.0000</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>jnardino</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica plus you've added commercials t...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:15:59 -0800</td>\n","      <td>NaN</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>570301083672813571</td>\n","      <td>neutral</td>\n","      <td>0.6837</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>yvonnalynn</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:15:48 -0800</td>\n","      <td>Lets Play</td>\n","      <td>Central Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>570301031407624196</td>\n","      <td>negative</td>\n","      <td>1.0000</td>\n","      <td>Bad Flight</td>\n","      <td>0.7033</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>jnardino</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica it's really aggressive to blast...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:15:36 -0800</td>\n","      <td>NaN</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>570300817074462722</td>\n","      <td>negative</td>\n","      <td>1.0000</td>\n","      <td>Can't Tell</td>\n","      <td>1.0000</td>\n","      <td>Virgin America</td>\n","      <td>NaN</td>\n","      <td>jnardino</td>\n","      <td>NaN</td>\n","      <td>0</td>\n","      <td>@VirginAmerica and it's a really big bad thing...</td>\n","      <td>NaN</td>\n","      <td>2015-02-24 11:14:45 -0800</td>\n","      <td>NaN</td>\n","      <td>Pacific Time (US &amp; Canada)</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fa927c9-9cd3-4857-8c22-a41267a0fbec')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4fa927c9-9cd3-4857-8c22-a41267a0fbec button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4fa927c9-9cd3-4857-8c22-a41267a0fbec');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":1}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P-vOkcxrxZsa","executionInfo":{"status":"ok","timestamp":1648549179491,"user_tz":-480,"elapsed":1188,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"fa4f183a-8eda-4ce5-ecc6-06943e3dafa2"},"source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from sklearn.feature_extraction.text import CountVectorizer\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","print('Done!')"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","Done!\n"]}]},{"cell_type":"markdown","metadata":{"id":"Sulkc6keJi1s"},"source":["## ***Q1***\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f7Lii-iFguM_","executionInfo":{"status":"ok","timestamp":1648549188786,"user_tz":-480,"elapsed":8878,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"f7689dc3-c2fa-4a75-9b67-372cb47f473e"},"source":["# Q1\n","## initialization\n","Q1_df = df\n","airline_sentiment = df['airline_sentiment']\n","\n","## Store airline names into an array\n","airline_names = df[\"airline\"].unique()\n","\n","## Remove punctuation\n","Q1_df['text'] = Q1_df['text'].str.replace(\"!\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\".\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"#\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\",\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\":\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\")\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"(\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"?\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"-\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"I\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"'\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"&\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\";\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"|\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('”', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('“', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('``', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('\"', \"\")\n","\n","# Stemming\n","from nltk.stem import PorterStemmer\n","ps = PorterStemmer()\n","for index, value in Q1_df['text'].items():\n","  # Lower Case\n","  value = ps.stem(value.lower())\n","  Q1_df['text'].iloc[index] = value\n","\n","## Remove @airline\n","for values in airline_names:\n","  # Add @ sign before airline names\n","  values = \"@\" + values\n","  # Remove empty space\n","  values = values.replace(\" \",\"\")\n","  if (values == \"@American\"):\n","    values = \"@AmericanAir\"\n","  elif (values == \"@Southwest\"):\n","    values = \"@SouthwestAir\"\n","  # Replace\n","  Q1_df['text'] = Q1_df['text'].str.replace(values, \"\")\n","\n","Q1_df['text'] = Q1_df['text'].str.replace(\"@USairways\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"@UsAirways\", \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"@JetBlue\", \"\")\n","\n","## Remove all lower case @airline\n","Q1_df['text'] = Q1_df['text'].str.replace('@united', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('@jetblue', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('@southwestair', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('@americanair', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('@usairways', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace('@virginamerica', \"\")\n","Q1_df['text'] = Q1_df['text'].str.replace(\"@\", \"\")\n","\n","# Preview\n","print(\"\\n\")\n","Q1_df['text'].head()"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:11: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n","  # This is added back by InteractiveShellApp.init_path()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n","  from ipykernel import kernelapp as app\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n","  app.launch_new_instance()\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:23: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n","/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1732: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  self._setitem_single_block(indexer, value, name)\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n"]},{"output_type":"execute_result","data":{"text/plain":["0                                   what dhepburn said\n","1     plus youve added commercials to the experienc...\n","2      didnt today must mean  need to take another ...\n","3     its really aggressive to blast obnoxious ente...\n","4              and its a really big bad thing about it\n","Name: text, dtype: object"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"veUeXv35OUJK","executionInfo":{"status":"ok","timestamp":1648549189699,"user_tz":-480,"elapsed":916,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"077ec638-c8e6-48fb-a7f4-3dea9641f47d"},"source":["## Split into three sentiment groups: positive, neutral, negative\n","Q1_positive = df[airline_sentiment == 'positive']\n","Q1_neutral = df[airline_sentiment == 'neutral']\n","Q1_negative = df[airline_sentiment == 'negative']\n","\n","## Positive sentiments\n","## Remove stopwords\n","wordlist = []\n","for index, value in Q1_positive['text'].items():\n","  stop_words = set(stopwords.words('english'))\n","  ## Tokenizing\n","  word_tokens = word_tokenize(value)\n","  for w in word_tokens:\n","     if not w in stop_words:\n","       wordlist.append(w)\n","\n","## Report\n","from collections import Counter\n","print(\"Top 10 words used in positive sentiment group are:\")\n","print(Counter(wordlist).most_common(10))"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 10 words used in positive sentiment group are:\n","[('thank', 594), ('thanks', 468), ('flight', 375), ('great', 234), ('service', 134), ('love', 130), ('get', 114), ('much', 109), ('customer', 108), ('good', 107)]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4QjIWpf1OXKr","executionInfo":{"status":"ok","timestamp":1648549190727,"user_tz":-480,"elapsed":1031,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"5c9bf966-a005-43b3-94f1-764f6a938dfa"},"source":["## Neutral sentiments\n","## Remove stopwords\n","wordlist = []\n","for index, value in Q1_neutral['text'].items():\n","  stop_words = set(stopwords.words('english'))\n","  ## Tokenizing\n","  word_tokens = word_tokenize(value)\n","  for w in word_tokens:\n","     if not w in stop_words:\n","       wordlist.append(w)\n","\n","## Report\n","print(\"Top 10 words used in neutral sentiment group are:\")\n","print(Counter(wordlist).most_common(10))"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 10 words used in neutral sentiment group are:\n","[('flight', 620), ('get', 238), ('need', 163), ('help', 162), ('please', 154), ('flights', 150), ('thank', 148), ('dm', 123), ('would', 122), ('fleek', 107)]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x_OcCNXOOaMF","executionInfo":{"status":"ok","timestamp":1648549193892,"user_tz":-480,"elapsed":3168,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"1e6d1400-255f-4a3b-d11c-63c45348357e"},"source":["## Negative sentiments\n","## Remove stopwords\n","wordlist = []\n","for index, value in Q1_negative['text'].items():\n","  stop_words = set(stopwords.words('english'))\n","  ## Tokenizing\n","  word_tokens = word_tokenize(value)\n","  for w in word_tokens:\n","     if w not in stop_words:\n","       wordlist.append(w)\n","\n","## Report\n","print(\"Top 10 words used in negative sentiment group are:\")\n","print(Counter(wordlist).most_common(10))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Top 10 words used in negative sentiment group are:\n","[('flight', 2939), ('get', 982), ('cancelled', 920), ('service', 636), ('help', 627), ('hold', 611), ('hours', 600), ('customer', 590), ('2', 534), ('time', 511)]\n"]}]},{"cell_type":"markdown","metadata":{"id":"x1OPvMNQJsqL"},"source":["## ***Q2***"]},{"cell_type":"code","metadata":{"id":"XKKfQ3BwnhGO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648549194609,"user_tz":-480,"elapsed":721,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"5e363928-a0cf-4317-c3e2-2d84e267bc98"},"source":["# Q2\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import cross_val_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import cross_val_score\n","from sklearn.metrics import classification_report\n","import numpy as np\n","\n","## Predictors and output\n","X = Q1_df['text']\n","Y = Q1_df['airline_sentiment']\n","vectorizer = TfidfVectorizer()\n","X = vectorizer.fit_transform(X)\n","\n","## Split dataset into 80% for training and 20% for testing\n","## stratify parameter ensures each airline is represented in training and testing data\n","X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, stratify = Y, random_state = 23)\n","\n","## Train\n","model = MultinomialNB()\n","model.fit(X_train, y_train)\n","print('Done Training')\n","\n","## Predict\n","y_pred = model.predict(X_test)\n","report = classification_report(y_test, y_pred, output_dict = True)\n","print(pd.DataFrame(report).transpose())\n","\n","## Cross Validation for not overfitting\n","scores = cross_val_score(model, X, Y, cv=10)"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Done Training\n","              precision    recall  f1-score     support\n","negative       0.661717  0.995640  0.795039  1835.00000\n","neutral        0.841121  0.145161  0.247593   620.00000\n","positive       0.833333  0.105708  0.187617   473.00000\n","accuracy       0.671790  0.671790  0.671790     0.67179\n","macro avg      0.778724  0.415503  0.410083  2928.00000\n","weighted avg   0.727429  0.671790  0.580993  2928.00000\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VFVAbHihdcrY","executionInfo":{"status":"ok","timestamp":1648549194610,"user_tz":-480,"elapsed":10,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"ccc0c260-2244-422f-c9f8-db36f9797cc1"},"source":["## Report\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","print('Accuracy score for this model is: %0.3f' % accuracy_score(y_test, y_pred))\n","print(\"Accuracy score for Cross Validation: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"],"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy score for this model is: 0.672\n","Accuracy score for Cross Validation: 0.66 (+/- 0.02)\n"]}]},{"cell_type":"markdown","metadata":{"id":"ftLnwtlzJuRI"},"source":["## ***Q3***\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oOEvxm-QnhIx","executionInfo":{"status":"ok","timestamp":1648549194610,"user_tz":-480,"elapsed":8,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"2bc62bf7-65c1-4302-9de2-938e0d395317"},"source":["# Q3\n","# Assuming fraction over number of sentiments specific to each airline\n","airline_names = df[\"airline\"].unique()\n","\n","# Frequency of positive, neutral, and negative sentiment for each airline\n","neg = {\"Virgin America\": 0 ,\"United\" : 0, \"Southwest\":0 , \"Delta\": 0, \"US Airways\" : 0, \"American\" : 0}\n","neutral = {\"Virgin America\": 0 ,\"United\" : 0, \"Southwest\":0 , \"Delta\": 0, \"US Airways\" : 0, \"American\" : 0}\n","pos = {\"Virgin America\": 0 ,\"United\" : 0, \"Southwest\":0 , \"Delta\": 0, \"US Airways\" : 0, \"American\" : 0}\n","\n","# Fraction of positives and negatives for each airline\n","neg_frac = {\"Virgin America\": 0 ,\"United\" : 0, \"Southwest\":0 , \"Delta\": 0, \"US Airways\" : 0, \"American\" : 0}\n","pos_frac = {\"Virgin America\": 0 ,\"United\" : 0, \"Southwest\":0 , \"Delta\": 0, \"US Airways\" : 0, \"American\" : 0}\n","\n","for airline in airline_names:\n","  # Extract airline series\n","  cur_airline = df[df['airline'] == airline]\n","\n","  # Find the frequency for positive, negative, and neutral\n","  counts = cur_airline['airline_sentiment'].value_counts()\n","\n","  # Append each value to our frequency dictionary\n","  neg[airline] = (counts[0])\n","  neutral[airline] = (counts[1])\n","  pos[airline] = (counts[2])\n","\n","  # Calculate total number of sentiments for each airline and calculate fraction\n","  total = counts[0] + counts[1] + counts[2]\n","  neg_frac[airline] = counts[0] / total\n","  pos_frac[airline] = counts[2] / total\n","\n","# Number of positives and negatives for each airline\n","print(\"Negative dict:\", neg)\n","print(\"Positive dict:\", pos)\n","print(\"Neutral dict:\", neutral)\n","\n","# Fraction of positives and negatives for each airline\n","print(\"\\nNegative fraction dict:\", neg_frac)\n","print(\"Positive fraction dict:\", pos_frac)\n","\n","# Sort the dictionary\n","print(\"\\nFraction with Negative sentiments in decreasing value:\")\n","sorted_name_neg = sorted(neg_frac, key=neg_frac.get, reverse = True)\n","for name in sorted_name_neg:\n","    print(name, neg_frac[name])\n","\n","print(\"\\nFraction with positive sentiments in decreasing value:\")\n","sorted_name_neg = sorted(pos_frac, key=pos_frac.get, reverse = True)\n","for name in sorted_name_neg:\n","    print(name, pos_frac[name])"],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Negative dict: {'Virgin America': 181, 'United': 2633, 'Southwest': 1186, 'Delta': 955, 'US Airways': 2263, 'American': 1960}\n","Positive dict: {'Virgin America': 152, 'United': 492, 'Southwest': 570, 'Delta': 544, 'US Airways': 269, 'American': 336}\n","Neutral dict: {'Virgin America': 171, 'United': 697, 'Southwest': 664, 'Delta': 723, 'US Airways': 381, 'American': 463}\n","\n","Negative fraction dict: {'Virgin America': 0.35912698412698413, 'United': 0.6889063317634746, 'Southwest': 0.4900826446280992, 'Delta': 0.4297929792979298, 'US Airways': 0.7768623412289736, 'American': 0.7104023196810438}\n","Positive fraction dict: {'Virgin America': 0.30158730158730157, 'United': 0.12872841444270017, 'Southwest': 0.23553719008264462, 'Delta': 0.2448244824482448, 'US Airways': 0.09234466186062479, 'American': 0.12178325480246466}\n","\n","Fraction with Negative sentiments in decreasing value:\n","US Airways 0.7768623412289736\n","American 0.7104023196810438\n","United 0.6889063317634746\n","Southwest 0.4900826446280992\n","Delta 0.4297929792979298\n","Virgin America 0.35912698412698413\n","\n","Fraction with positive sentiments in decreasing value:\n","Virgin America 0.30158730158730157\n","Delta 0.2448244824482448\n","Southwest 0.23553719008264462\n","United 0.12872841444270017\n","American 0.12178325480246466\n","US Airways 0.09234466186062479\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fD26v_P4dSZV","executionInfo":{"status":"ok","timestamp":1648549194611,"user_tz":-480,"elapsed":7,"user":{"displayName":"Chia-Yuan Chang","userId":"01037799148776894861"}},"outputId":"9a8df20e-2b9f-4d9d-d493-47056113a9ce"},"source":["# Report\n","print(\"The top 3 airlines in terms of the fraction of negative tweets are: US Airways, American, United\")\n","print(\"The top 3 airlines in terms of the fraction of positive tweets are: Virgin America, Delta, Southwest\")"],"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["The top 3 airlines in terms of the fraction of negative tweets are: US Airways, American, United\n","The top 3 airlines in terms of the fraction of positive tweets are: Virgin America, Delta, Southwest\n"]}]}]}